---
title: Agents
description: Agents agregam e curam tools de múltiplas connections em um único endpoint MCP
icon: Share2
---

## O que é um Agent?

Um **Agent** é um "MCP virtual": ele expõe um único endpoint MCP que agrega tools/resources/prompts de múltiplas **connections**.

## Estratégias de exposição de tools

Agents também controlam **como as tools são expostas** (útil quando o surface cresce).
Essas estratégias vêm por padrão:

### Passthrough (baseline)

- Expõe todas as tools do agent diretamente via `tools/list`.
- Melhor para superfícies pequenas e comportamento determinístico.

### Smart tool selection

- Expõe meta-tools para descoberta e execução direcionada:
  - **GATEWAY_SEARCH_TOOLS** (busca por palavras-chave)
  - **GATEWAY_DESCRIBE_TOOLS** (schemas completos)
  - **GATEWAY_CALL_TOOL** (executa a tool escolhida)
- Objetivo: manter a lista de tools pequena e deixar o client pedir detalhes sob demanda.

### Code execution

- Expõe meta-tools para descoberta + execução sandboxed:
  - **GATEWAY_SEARCH_TOOLS**
  - **GATEWAY_DESCRIBE_TOOLS**
  - **GATEWAY_RUN_CODE** (executa JS em um sandbox que pode chamar tools)
- Objetivo: reduzir overhead de exposição em superfícies grandes movendo parte do trabalho para um runtime controlado.

## O Default Agent (criado automaticamente por org)

Toda organização nova recebe um **Default Agent**:

- **Strategy**: `passthrough`
- **Mode**: `exclusion`
- **Exclusões padrão**: a connection interna **Mesh MCP** (tools de administração) e a connection da **Store/Registry** são excluídas por padrão
- **Comportamento**: todo o resto entra automaticamente — então, conforme você conecta Conexões, esse endpoint vira o Agent "com todas as tools da org"

Esse é o endpoint que muitos times usam como a superfície MCP principal da organização.

## Benchmark: tradeoffs de estratégia

Rodamos um benchmark aqui: [MCP Agent Benchmark (GitHub Actions run)](https://github.com/decocms/mesh/actions/runs/20584203227).

**Resumo (alto nível):**

- **Superfície pequena (~10 tools)**:
  - **passthrough** usou menos tokens, mas teve menor sucesso que **code_execution**
  - **smart_tool_selection** foi o menos confiável nessa execução
- **Superfície grande (~128 tools)**:
  - **code_execution** reduziu tokens vs **passthrough** e teve o maior sucesso
  - **smart_tool_selection** foi o mais caro em tokens nessa execução

Se você quiser os números brutos, abra o run e baixe o artifact **benchmark-results**.


